Input Notebook:  4098_early_training_phase_diagram_zeros.ipynb
Output Notebook: output3.ipynb
Executing:   0%|          | 0/29 [00:00<?, ?cell/s]Executing notebook with kernel: python3
Executing:   3%|▎         | 1/29 [00:00<00:20,  1.36cell/s]Executing:   7%|▋         | 2/29 [00:02<00:28,  1.07s/cell]Executing:  28%|██▊       | 8/29 [00:04<00:09,  2.14cell/s]Executing:  48%|████▊     | 14/29 [00:04<00:03,  4.47cell/s]Executing:  59%|█████▊    | 17/29 [00:20<00:02,  4.47cell/s]Executing:  62%|██████▏   | 18/29 [00:25<00:21,  1.96s/cell]2024-11-05 22:44:58.876717: W external/xla/xla/tsl/framework/bfc_allocator.cc:306] Allocator (GPU_0_bfc) ran out of memory trying to allocate 16.52GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.
2024-11-05 22:45:10.479780: W external/xla/xla/tsl/framework/bfc_allocator.cc:306] Allocator (GPU_0_bfc) ran out of memory trying to allocate 16.52GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.
2024-11-05 22:45:25.759461: W external/xla/xla/tsl/framework/bfc_allocator.cc:306] Allocator (GPU_0_bfc) ran out of memory trying to allocate 17.52GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.
2024-11-05 22:45:32.877679: E external/xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng20{k2=6,k3=0} for conv (f32[512,512,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[512,512,32,32]{3,2,1,0}, f32[512,512,32,32]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target="__cudnn$convBackwardFilter", backend_config={"cudnn_conv_backend_config":{"activation_mode":"kNone","conv_result_scale":1,"leakyrelu_alpha":0,"side_input_scale":0},"force_earliest_schedule":false,"operation_queue_id":"0","wait_on_operation_queues":[]} is taking a while...
2024-11-05 22:45:32.914756: E external/xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.037231078s
Trying algorithm eng20{k2=6,k3=0} for conv (f32[512,512,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[512,512,32,32]{3,2,1,0}, f32[512,512,32,32]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target="__cudnn$convBackwardFilter", backend_config={"cudnn_conv_backend_config":{"activation_mode":"kNone","conv_result_scale":1,"leakyrelu_alpha":0,"side_input_scale":0},"force_earliest_schedule":false,"operation_queue_id":"0","wait_on_operation_queues":[]} is taking a while...
2024-11-05 22:45:33.914902: E external/xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng1{k2=6,k3=0} for conv (f32[512,512,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[512,512,32,32]{3,2,1,0}, f32[512,512,32,32]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target="__cudnn$convBackwardFilter", backend_config={"cudnn_conv_backend_config":{"activation_mode":"kNone","conv_result_scale":1,"leakyrelu_alpha":0,"side_input_scale":0},"force_earliest_schedule":false,"operation_queue_id":"0","wait_on_operation_queues":[]} is taking a while...
2024-11-05 22:45:33.954352: E external/xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.039534888s
Trying algorithm eng1{k2=6,k3=0} for conv (f32[512,512,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[512,512,32,32]{3,2,1,0}, f32[512,512,32,32]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target="__cudnn$convBackwardFilter", backend_config={"cudnn_conv_backend_config":{"activation_mode":"kNone","conv_result_scale":1,"leakyrelu_alpha":0,"side_input_scale":0},"force_earliest_schedule":false,"operation_queue_id":"0","wait_on_operation_queues":[]} is taking a while...
2024-11-05 22:45:39.698668: E external/xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng19{k5=1,k6=0,k7=1,k10=6} for conv (f32[512,512,32,32]{3,2,1,0}, u8[0]{0}) custom-call(f32[512,512,32,32]{3,2,1,0}, f32[512,512,3,3]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target="__cudnn$convBackwardInput", backend_config={"cudnn_conv_backend_config":{"activation_mode":"kNone","conv_result_scale":1,"leakyrelu_alpha":0,"side_input_scale":0},"force_earliest_schedule":false,"operation_queue_id":"0","wait_on_operation_queues":[]} is taking a while...
2024-11-05 22:45:39.895229: E external/xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.196649219s
Trying algorithm eng19{k5=1,k6=0,k7=1,k10=6} for conv (f32[512,512,32,32]{3,2,1,0}, u8[0]{0}) custom-call(f32[512,512,32,32]{3,2,1,0}, f32[512,512,3,3]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target="__cudnn$convBackwardInput", backend_config={"cudnn_conv_backend_config":{"activation_mode":"kNone","conv_result_scale":1,"leakyrelu_alpha":0,"side_input_scale":0},"force_earliest_schedule":false,"operation_queue_id":"0","wait_on_operation_queues":[]} is taking a while...
2024-11-05 22:46:29.434575: W external/xla/xla/tsl/framework/bfc_allocator.cc:306] Allocator (GPU_0_bfc) ran out of memory trying to allocate 13.69GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.
Executing:  69%|██████▉   | 20/29 [2:45:04<2:25:26, 969.56s/cell]Executing:  76%|███████▌  | 22/29 [2:45:05<1:28:22, 757.52s/cell]Executing:  83%|████████▎ | 24/29 [2:45:06<48:06, 577.31s/cell]  Executing:  90%|████████▉ | 26/29 [2:45:06<21:32, 430.82s/cell]Executing:  97%|█████████▋| 28/29 [2:45:06<05:16, 316.23s/cell]Executing: 100%|██████████| 29/29 [2:45:09<00:00, 341.71s/cell]
